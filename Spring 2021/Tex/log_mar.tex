\documentclass[11pt]{article}
%you can look for fun LaTeX packages to use hereasdf

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{amsthm}

\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}

%fun commands for fun sets
%make sure to use these in math mode
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\m}{\mathcal{M}}
\newcommand{\Tt}{\mathcal{T}}
\newcommand{\pa}{\partial}
\newcommand{\dD}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}



\oddsidemargin0cm
\topmargin-2cm    
\textwidth16.5cm   
\textheight23.5cm  

\newcommand{\question}[2] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1: #2} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

\newcommand{\myname}{Alex Havrilla}
\newcommand{\myandrew}{alumhavr}
\newcommand{\myhwnum}{Hw 1}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Prop}
\theoremstyle{remark}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{defi}{Def}
\newtheorem{apps}{Application}
\newtheorem{quest}{Question}
\newtheorem{ans}{Answer}
\newtheorem{interest}{Interesting}
\newtheorem{theme}{Theme}
\newtheorem{back}{Background}
\newtheorem{idea}{Idea}
\newtheorem{example}{Example}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
\pagestyle{fancyplain}
\lhead{\fancyplain{}{\textbf{HW\myhwnum}}}      % Note the different brackets!
\rhead{\fancyplain{}{\myname\\ \myandrew}}
\chead{\fancyplain{}{\mycourse}}

\linespread{1.3}

\title{Deadlines}

\begin{document}

\maketitle

\section{3/9}

\subsection{Goals}

\begin{enumerate}
	\item Work on thesis: finish 2 sections
	\item Work on complex: finish 2 problems
	\item Work on drl: finish 1 problem
\end{enumerate}

\subsection{DRL}

\begin{remark}
	Recall: Goal is to learn $v_{\pi}(s)$ from episodes of experiece under $\pi$.(In MC or TD learning)

	For Monte Carlo: Update $V(S_t) := V(S_t) + \alpha(G_t -V(S_t))$ over random trajectories
\end{remark}

\begin{remark}
	Monte-Carlo: $G_t$ is unbiased estimator of $V_{\pi}(S_t)$. But potentially high variance

	Temportal Difference: $R_{t+1}+\gamma V(S_{t+1})$ is biased estimator but lower variance. True target $R_{t+1} + \gamma v_{\pi}(S_{t+1})$ is unbiased estimate of $v_{\pi}(S_t)$
\end{remark}

\begin{remark}
	Note this is idea of bootstrapping: using data to generate model which we then use in estimator: estimator uses another estimator.
\end{remark}

\begin{remark}
	SARAS and q-learning method of updating q values
\end{remark}

\end{document}

